{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Fahim Tajwar\n",
    "\n",
    "from project_code.label_loader import *\n",
    "from project_code.image_loader import *\n",
    "from project_code.util import *\n",
    "from project_code.models import *\n",
    "from project_code.model_trainer import *\n",
    "from project_code.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell dies', 'grows sparse', 'grows dense'}\n",
      "{'cell dies': 0, 'grows sparse': 1, 'grows dense': 2}\n",
      "tensor([0.0260, 0.0097, 0.0294])\n"
     ]
    }
   ],
   "source": [
    "file_name_1 = '/Users/fahimtajwar/Academics/cs231/labels_cells_only.xlsx'\n",
    "file_name_2 = '/Users/fahimtajwar/Academics/cs231/classes_800.xlsx'\n",
    "file_names = [file_name_1, file_name_2]\n",
    "\n",
    "label_reader = Label_Reader(file_names)\n",
    "weight_vector = label_reader.get_weight_vector()\n",
    "print(label_reader.get_all_labels())\n",
    "print(label_reader.get_label_to_label_id_map())\n",
    "print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([351, 3, 224, 224])\n",
      "{1004: 0, 1006: 1, 1015: 2, 1016: 3, 1018: 4, 1019: 5, 1023: 6, 1027: 7, 1036: 8, 1037: 9, 1046: 10, 1055: 11, 1060: 12, 1062: 13, 1063: 14, 1064: 15, 1078: 16, 1086: 17, 1091: 18, 1098: 19, 1100: 20, 1111: 21, 1122: 22, 1125: 23, 1130: 24, 1134: 25, 1141: 26, 1142: 27, 1146: 28, 1153: 29, 1171: 30, 1175: 31, 1176: 32, 1187: 33, 1194: 34, 1233: 35, 1242: 36, 1254: 37, 1265: 38, 1303: 39, 1324: 40, 1327: 41, 1337: 42, 1389: 43, 1416: 44, 1432: 45, 1457: 46, 1460: 47, 1476: 48, 1480: 49, 1516: 50, 1520: 51, 1524: 52, 1569: 53, 1591: 54, 1600: 55, 1607: 56, 1608: 57, 1611: 58, 1614: 59, 1622: 60, 1644: 61, 1646: 62, 1667: 63, 1672: 64, 1679: 65, 1685: 66, 1689: 67, 1693: 68, 1714: 69, 1719: 70, 1733: 71, 1736: 72, 1739: 73, 1754: 74, 1770: 75, 1771: 76, 1772: 77, 1775: 78, 1779: 79, 1784: 80, 1785: 81, 1786: 82, 1791: 83, 1794: 84, 1801: 85, 1804: 86, 1806: 87, 1807: 88, 1811: 89, 1812: 90, 1813: 91, 1815: 92, 1819: 93, 1824: 94, 1825: 95, 1828: 96, 1829: 97, 1831: 98, 1833: 99, 1835: 100, 1838: 101, 1848: 102, 1849: 103, 1853: 104, 1857: 105, 1859: 106, 1863: 107, 1866: 108, 1870: 109, 1876: 110, 1879: 111, 1880: 112, 1891: 113, 1893: 114, 1900: 115, 1906: 116, 1913: 117, 1918: 118, 1931: 119, 1934: 120, 1939: 121, 1940: 122, 1943: 123, 1945: 124, 1947: 125, 1958: 126, 1962: 127, 1967: 128, 1974: 129, 1977: 130, 1979: 131, 1983: 132, 1992: 133, 1993: 134, 1998: 135, 2001: 136, 2011: 137, 2017: 138, 2018: 139, 2023: 140, 2029: 141, 2031: 142, 2032: 143, 2040: 144, 2046: 145, 2082: 146, 2091: 147, 2094: 148, 2096: 149, 2099: 150, 2101: 151, 2107: 152, 2111: 153, 2114: 154, 2122: 155, 2124: 156, 2134: 157, 2135: 158, 2137: 159, 2147: 160, 2164: 161, 2179: 162, 2193: 163, 2194: 164, 2199: 165, 2210: 166, 2215: 167, 2227: 168, 2228: 169, 2231: 170, 2239: 171, 2249: 172, 2253: 173, 2278: 174, 2285: 175, 2291: 176, 2299: 177, 2337: 178, 2342: 179, 2344: 180, 2346: 181, 2351: 182, 2360: 183, 2361: 184, 2368: 185, 2387: 186, 2388: 187, 2389: 188, 2393: 189, 2397: 190, 2406: 191, 2408: 192, 2414: 193, 2417: 194, 2424: 195, 2432: 196, 2438: 197, 2484: 198, 2501: 199, 2502: 200, 2541: 201, 2543: 202, 2569: 203, 2578: 204, 2579: 205, 2625: 206, 2634: 207, 2640: 208, 2662: 209, 2666: 210, 2684: 211, 2693: 212, 2751: 213, 2800: 214, 2810: 215, 2820: 216, 2832: 217, 2839: 218, 2847: 219, 2853: 220, 2857: 221, 2862: 222, 2866: 223, 2870: 224, 2881: 225, 2891: 226, 2899: 227, 2920: 228, 2939: 229, 2942: 230, 2955: 231, 2971: 232, 2972: 233, 2986: 234, 2991: 235, 100: 236, 101: 237, 111: 238, 121: 239, 128: 240, 134: 241, 136: 242, 14: 243, 153: 244, 159: 245, 167: 246, 169: 247, 17: 248, 183: 249, 187: 250, 197: 251, 201: 252, 202: 253, 206: 254, 221: 255, 242: 256, 250: 257, 255: 258, 257: 259, 269: 260, 272: 261, 275: 262, 278: 263, 286: 264, 29: 265, 292: 266, 295: 267, 307: 268, 317: 269, 321: 270, 325: 271, 326: 272, 329: 273, 331: 274, 347: 275, 355: 276, 358: 277, 360: 278, 371: 279, 374: 280, 381: 281, 383: 282, 384: 283, 387: 284, 389: 285, 391: 286, 399: 287, 412: 288, 413: 289, 418: 290, 419: 291, 42: 292, 424: 293, 434: 294, 450: 295, 451: 296, 455: 297, 456: 298, 464: 299, 483: 300, 499: 301, 517: 302, 518: 303, 52: 304, 522: 305, 525: 306, 536: 307, 54: 308, 542: 309, 548: 310, 559: 311, 561: 312, 564: 313, 569: 314, 572: 315, 579: 316, 587: 317, 588: 318, 590: 319, 593: 320, 608: 321, 614: 322, 62: 323, 623: 324, 635: 325, 653: 326, 667: 327, 67: 328, 677: 329, 68: 330, 683: 331, 695: 332, 696: 333, 702: 334, 703: 335, 709: 336, 723: 337, 724: 338, 738: 339, 739: 340, 75: 341, 750: 342, 753: 343, 755: 344, 76: 345, 767: 346, 785: 347, 91: 348, 96: 349, 98: 350}\n"
     ]
    }
   ],
   "source": [
    "prefix = \"/Users/fahimtajwar/Academics/cs231/project_data_well_2/well2_data/well\"\n",
    "suffix = \"_well.png\"\n",
    "\n",
    "all_well_ids = label_reader.get_all_well_ids()\n",
    "si = Single_Image_Loader(5, all_well_ids, prefix, suffix)\n",
    "tensor = si.get_image_tensor()\n",
    "well_id_to_image_id_map = si.get_well_to_image_id_map()\n",
    "print(tensor.shape)\n",
    "print(well_id_to_image_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "[ 667 1779 1947 2137 1476   17  374 2107 1591  564 2484  724 2368 2832\n",
      " 2199 1153 1801 1078   42 1791 1962  206  202 1815 2955  579 1689 1876\n",
      " 2389  295  518  134  561  167 2179  355  608  464  785  269 2847 2939\n",
      " 1943 1833 2096  257  197  683  723 1046 1806 1913 1520 2291 1685 1524\n",
      "  695   52 2899  483   67  593 1804 2820  517 2971 2114 1771  307 1091\n",
      " 1233  331 2029  412 1967 2046 2578 1432 1812 1175  169  450 2502 2684\n",
      " 1125  278 1064 1870  696 2543 2253  286 1337 1015 2666 1036  753 2278\n",
      " 2031 1303  360 1714 2011 2040 1122 1416  325 2438 2361 2147 1828  738\n",
      "  623 2972 1829 2346 2101   14 2393  391 2417  419 2424 1918  635  383\n",
      " 1993 2023 2094 1770 2387  255 2942   91 1849  275 2408 1023  201 2017\n",
      " 2091 1176 1784 1977 2285 1607 1060 1934  750 1879 1838 1086 2344  413\n",
      " 1998   62 2662 2870 1754 1460  153 2640 1667 1831 2991  434 1813 1786\n",
      " 2853 1027 2342 1931 2866 2751 2001 2215 1457 2406 1142 1111 1824 1739\n",
      " 1004  272   98 1835 1811  384 2239 1063 1516  522 2193  358 1608  347\n",
      "  250 2857 2299  399   29 1893 1600 2634  128 2881 1055 1857 1389 1324\n",
      "  767  590  321  317 1736  702 2018 2625 1187 1644 2862  159 1646  456\n",
      " 1016 2111 1679  329 1327 1775 1719  677 2210 2800  111 1825  755 1958\n",
      " 1265 1794 1018 1098 2134 1807 2032   68 1939 1974  587  588  499 2099\n",
      " 2891 1945 1785 2164 1979  739  101  221 2501 1819  424 2397  389 1254\n",
      " 1992 1733 1863 2541 1480 1130 2135 2414 2810 1062 1880  418 1891 1134]\n",
      "35\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "input_size = 3 * 224 * 224\n",
    "num_classes = 3\n",
    "\n",
    "label_to_label_id = label_reader.label_to_label_id\n",
    "label_id_to_label_map = label_reader.get_label_id_to_label_map()\n",
    "#print(label_id_to_label_map)\n",
    "\n",
    "Y_label = label_reader.get_label_map()\n",
    "for key in Y_label:\n",
    "    Y_label[key] = label_to_label_id[Y_label[key]]\n",
    "\n",
    "#print(Y_label)\n",
    "\n",
    "label_id_train, label_id_val, label_id_test = get_dataset_split(Y_label)\n",
    "print(len(label_id_train))\n",
    "print(label_id_train)\n",
    "print(len(label_id_val))\n",
    "print(len(label_id_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Augmented_Dataset(tensor, label_id_train, Y_label, well_id_to_image_id_map, \n",
    "                                 final_transformation_choice)\n",
    "validation_set = Augmented_Dataset(tensor, label_id_val, Y_label, well_id_to_image_id_map, transform_normalization)\n",
    "test_set = Augmented_Dataset(tensor, label_id_test, Y_label, well_id_to_image_id_map, transform_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 320\n",
    "validation_batch_size = 1\n",
    "test_batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = validation_set, \n",
    "                                          batch_size = validation_batch_size, \n",
    "                                          shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set, \n",
    "                                          batch_size = test_batch_size, \n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ad3e33247182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model = Model(resnet, training_set, training_batch_size, learning_rate, label_id_to_label_map, \n\u001b[1;32m      3\u001b[0m               weight = weight_vector, imbalanced_class = False, num_epochs = 30, verbose = True)\n",
      "\u001b[0;32m~/Academics/cs231/Code/project_code/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/Academics/cs231/Code/project_code/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "resnet = Resnet_Model(num_classes = 3)\n",
    "model = Model(resnet, training_set, training_batch_size, learning_rate, label_id_to_label_map, \n",
    "              weight = weight_vector, imbalanced_class = False, num_epochs = 30, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
