{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from project_code.read_labels import *\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_well_specific_string_prefix(well_num):\n",
    "    well_str = \"\"\n",
    "    if well_num <= 9:\n",
    "        well_str = \"000\"\n",
    "    elif well_num <= 99:\n",
    "        well_str = \"00\"\n",
    "    elif well_num <= 999:\n",
    "        well_str = \"0\"\n",
    "    \n",
    "    return well_str\n",
    "\n",
    "def get_day_specific_string_prefix(day):\n",
    "    day_str = \"_day\"\n",
    "    if day <= 9:\n",
    "        day_str = \"_day0\"\n",
    "    \n",
    "    return day_str\n",
    "\n",
    "def make_list_of_image_names(min_well, max_well, min_day, max_day, prefix, suffix):\n",
    "    well_values = range(min_well, max_well + 1)\n",
    "    day_values = range(min_day, max_day + 1)\n",
    "    prefix = \"/home/fahimtajwar/final_project/project_data/labelled_data/well\"\n",
    "    suffix = \"_well.png\"\n",
    "    \n",
    "    image_names = []\n",
    "    for well_num in well_values:\n",
    "        for day in day_values:\n",
    "            well_str = get_well_specific_string_prefix(well_num)\n",
    "            day_str = get_day_specific_string_prefix(day)\n",
    "            name = prefix + well_str + str(well_num) + day_str + str(day) + suffix\n",
    "            image_names.append(name)\n",
    "    \n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(min_well, max_well, min_day, max_day, \n",
    "                prefix = \"/home/fahimtajwar/final_project/project_data/labelled_data/well\", \n",
    "                suffix = \"_well.png\"):\n",
    "    \n",
    "    image_names = make_list_of_image_names(min_well, max_well, min_day, max_day, prefix, suffix)\n",
    "    images = []\n",
    "    for name in image_names:\n",
    "        img = Image.open(name)\n",
    "        images.append(img)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0]\n",
    "    return x.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors_one(min_well, max_well, min_day, max_day, \n",
    "                prefix = \"/home/fahimtajwar/final_project/project_data/labelled_data/well\", \n",
    "                suffix = \"_well.png\"):\n",
    "    \n",
    "    image_names = make_list_of_image_names(min_well, max_well, min_day, max_day, prefix, suffix)\n",
    "    listTens = []\n",
    "    numAp = 0\n",
    "    for name in image_names:\n",
    "        img = Image.open(name)\n",
    "        t_img = Variable(to_tensor(scaler(img)))\n",
    "        listTens.append(t_img)\n",
    "        \n",
    "    return torch.stack(listTens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(min_well, max_well, min_day, max_day, \n",
    "                prefix = \"/home/fahimtajwar/final_project/project_data/labelled_data/well\", \n",
    "                suffix = \"_well.png\"):\n",
    "    \n",
    "    image_names = make_list_of_image_names(min_well, max_well, min_day, max_day, prefix, suffix)\n",
    "    listTens = []\n",
    "    count = 0\n",
    "    currT = []\n",
    "    numAp = 0\n",
    "    for name in image_names:\n",
    "        img = Image.open(name)\n",
    "        t_img = Variable(to_tensor(scaler(img)))\n",
    "        count += 1\n",
    "        currT.append(t_img)\n",
    "        if count % 5==0:\n",
    "            numAp += 1\n",
    "            tenS = torch.stack(currT, dim=1)\n",
    "            tenS = tenS.squeeze(0)\n",
    "            listTens.append(tenS)\n",
    "            currT = []\n",
    "            \n",
    "    return torch.stack(listTens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_name = \"/home/fahimtajwar/final_project/project_data/classes_800.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_map(label_file_name):\n",
    "    label_reader = Label_Reader(label_file_name)\n",
    "    return label_reader.get_label_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = get_tensors(0, 799, 5, 5)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_reader = Label_Reader(label_file_name)\n",
    "label_to_label_id = label_reader.label_to_label_id\n",
    "Y_label = get_label_map(label_file_name)\n",
    "\n",
    "for key in Y_label:\n",
    "    Y_label[key] = label_to_label_id[Y_label[key]]\n",
    "\n",
    "label_id_train = range(0, 119)\n",
    "label_id_val= range(120, 159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        # Load data and get label\n",
    "        y = self.labels[ID]\n",
    "        X = X_data[ID]\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "training_set = Dataset(label_id_train, Y_label)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(label_id_val, Y_label)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        flat = flatten(x)\n",
    "        out = self.linear(flat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4 * 224 * 224 * 5\n",
    "num_classes = 6\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=validation_set, \n",
    "                                          batch_size= 1, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, verbose = True):\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "    loss_table = []\n",
    "    \n",
    "    # Training the Model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                % (epoch+1, num_epochs, i+1, len(training_set)//batch_size, loss.data))\n",
    "        loss_table.append(loss)\n",
    "        \n",
    "    plt.plot(loss_table)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Cross entropy training loss')\n",
    "    plt.title('Training loss history')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "log_reg_on_day_5_images = LogisticRegression(input_size, num_classes)\n",
    "train(log_reg_on_day_5_images, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = log_reg_on_day_5_images(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 100 validation images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_analysis\n",
    "# first find the number of members in each class\n",
    "\n",
    "labels_map = get_label_map(label_file_name)\n",
    "label_to_label_id = label_reader.label_to_label_id\n",
    "label_id_to_label = label_reader.label_id_to_label\n",
    "\n",
    "map_count = {}\n",
    "for key in labels_map:\n",
    "    label = labels_map[key]\n",
    "    if label not in map_count:\n",
    "        map_count[label] = 1\n",
    "    else:\n",
    "        map_count[label] += 1\n",
    "        \n",
    "print(map_count)\n",
    "\n",
    "D = map_count\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "li = [\"transient\", \"debris\", \"cell dies\", \"sparse\", \"artifact\", \"dense\"]\n",
    "plt.xticks(range(len(D)), li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_map = {}\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        if labels[0].item() not in correct_map:\n",
    "            if predicted[0] == labels[0]:\n",
    "                correct_map[labels[0].item()] = 1\n",
    "            else:\n",
    "                correct_map[labels[0].item()] = 0\n",
    "        \n",
    "        else:\n",
    "            if predicted[0] == labels[0]:\n",
    "                correct_map[labels[0].item()] += 1\n",
    "                \n",
    "    accuracy = (100.0 * correct) / total\n",
    "    return accuracy, correct_map\n",
    "\n",
    "accuracy, correct_map = test_model(log_reg_on_day_5_images, test_loader)\n",
    "print(\"accuracy %f\" % accuracy)\n",
    "\n",
    "def get_correct_numbers_per_label(correct_map, label_id_to_label):\n",
    "    new_map = {}\n",
    "    for key in correct_map:\n",
    "        new_map[label_id_to_label[key]] = correct_map[key]\n",
    "        \n",
    "    return new_map\n",
    "    \n",
    "    \n",
    "print(get_correct_numbers_per_label(correct_map, label_id_to_label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(4, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(56 * 56 * 16 * 5, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ConvNet(num_classes = 6)\n",
    "train(cnn_model, train_loader, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, correct_map = test_model(cnn_model, test_loader)\n",
    "print(\"accuracy %f\" % accuracy)\n",
    "\n",
    "def get_correct_numbers_per_label(correct_map, label_id_to_label):\n",
    "    new_map = {}\n",
    "    for key in correct_map:\n",
    "        new_map[label_id_to_label[key]] = correct_map[key]\n",
    "        \n",
    "    return new_map\n",
    "    \n",
    "    \n",
    "print(get_correct_numbers_per_label(correct_map, label_id_to_label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
